# Pandas-Data-Frame-Using-Web-Scraping
--> Importing three required modules

      1)Pandas Module

      2)Requests Module

      3)Beautiful Soup

--> Whenever we are going to get the url link and run the code using get method and requests module it gives us the response 402

--> That means we need to add the headers to know the HTTP request is going from the browser not from the bots etc.

--> After adding the header whenever we are going to run the data we will get the HTTP Content.

--> So we are converting the given content to the textual format.

--> to get the same type of the data which was extracted through the web we use to print by using predefined  prettify function

--> We are Using the beautiful soup function and adding the webpage url and also the lxml module

--> And trying to Manipulating the information and commonly used functions are

                      1)find_all
                      2)find
--> And to extract the particular information we are using the class parameter in find , find_all built-in function

--> getting the request from single page and adding the data in the empty data frame and returning the pandas empty data frame 

-----------------------------------------------------------------------------------------------------------------------------------
          *********************AUTHOR:MUDITH NAHATA**************************************
-----------------------------------------------------------------------------------------------------------------------------------
